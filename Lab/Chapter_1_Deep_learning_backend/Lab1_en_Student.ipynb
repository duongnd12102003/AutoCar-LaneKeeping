{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 1 ‚Äì Deep Learning Backends for Lane Segmentation\n",
        "---\n",
        "## Overview\n",
        "\n",
        "This lab introduces the **deep learning perception backends** used for lane segmentation in the AutoCar-Kit Lane Keeping system.\n",
        "\n",
        "You will explore how multiple state-of-the-art segmentation models can be integrated as **interchangeable perception modules**, producing consistent binary lane masks for downstream processing.\n",
        "\n",
        "The output of this lab serves as the **input foundation** for all subsequent stages, including ROI filtering, BEV transformation, lane geometry estimation, and steering control.\n",
        "\n",
        "---\n",
        "In the overall project pipeline, the first block is:\n",
        "\n",
        "> **Deep Learning Backend Segmentation** (YOLOv8 / PIDNet / TwinLiteNet / BiSeNetV2)\n",
        "> ‚Üí generates **binary lane mask `mask01`**\n",
        "\n",
        "Lab 1 focuses on the backend:\n",
        "\n",
        "- Correctly initialize the backend lane segmentation.\n",
        "\n",
        "- Call `infer_mask01(frame_bgr)` to generate `mask01`.\n",
        "\n",
        "- Visualize the segmentation results.\n",
        "\n",
        "- Save `Lab1_mask01_*.png` for 10 frames (reusable in Lab 2).\n",
        "\n",
        "> This is the **student** version: important code sections are hidden using `...` + general hints. You need to read the original code in the `AI/` folder yourself to complete the process."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "762eb362",
      "metadata": {},
      "source": [
        "# Code Reading Suggestions:\n",
        "\n",
        "- Find the `build_lane()` function in `AI/main.py` to see how the project initializes the backend.\n",
        "\n",
        "- View the configuration parameters of each model in `AI/configs/config.py`.\n",
        "\n",
        "- In Tasks 4‚Äì5‚Äì6, the infer method you need to use is the same method\n",
        "\n",
        "that the project is using to generate `mask01` before passing it to the ROI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Learning Objectives\n",
        "\n",
        "- Understand the 4-backend lane segmentation structure of the project.\n",
        "\n",
        "- Initialize a backend from `model_name`.\n",
        "\n",
        "- Use `infer_mask01` to create a binary lane mask.\n",
        "\n",
        "- Visually compare the results of each backend.\n",
        "\n",
        "- Prepare the `Lab1_mask01_*.png` file for Lab 2."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "053e0772",
      "metadata": {},
      "source": [
        "# 0. Preparing the environment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 0.1. Importing basic libraries\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 0.2. Set the path to the AI ‚Äã‚Äãfolder and import the configuration + backend\n",
        "\n",
        "ROOT = Path(\"../..\").resolve()\n",
        "AI_ROOT = ROOT / \"AI\"\n",
        "sys.path.append(str(AI_ROOT))\n",
        "\n",
        "print(\"Project ROOT:\", ROOT)\n",
        "print(\"AI ROOT     :\", AI_ROOT)\n",
        "\n",
        "from configs import config as C\n",
        "\n",
        "from LaneDetection.backends.yolov8_backend import YoloV8Backend\n",
        "from LaneDetection.backends.pidnet_backend import PIDNetBackend\n",
        "from LaneDetection.backends.twinlite_backend import TwinLiteBackend\n",
        "from LaneDetection.backends.bisenetv2_backend import BiseNetV2Backend\n",
        "\n",
        "print(\"LANE_MODEL  (default):\", C.LANE_MODEL)\n",
        "print(\"LANE_WEIGHTS(default):\", C.LANE_WEIGHTS)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d430b0fb",
      "metadata": {},
      "source": [
        "# If the machine only has a CPU, run the cell below to force the CPU to be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4a219ab",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "print(\"Before override, C.DEVICE =\", C.DEVICE)\n",
        "print(\"torch.cuda.is_available():\", torch.cuda.is_available())\n",
        "C.DEVICE = \"cpu\"\n",
        "\n",
        "print(\"After override,  C.DEVICE =\", C.DEVICE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Build a deep learning backend"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a589308",
      "metadata": {},
      "source": [
        "### Overview\n",
        "\n",
        "In the project's real pipeline, the backend module acts as the \"perception brain\": it receives raw images from the camera and returns a binary mask lane.\n",
        "\n",
        "The AI/main.py file shows you how the system actually creates the backend corresponding to the selected model (YOLOv8 / PIDNet / TwinLite / BiSeNet).\n",
        "\n",
        "All backends are built from configuration and weights:\n",
        "\n",
        "- Configuration contains technical specifications ‚Üí input size, number of classes, threshold, PIDNet/TwinLite architecture.\n",
        "\n",
        "- Weights contain the learned parameters of the model.\n",
        "\n",
        "When writing build_backend(model_name) in this Lab, you are simulating the backend initialization process of a real system.\n",
        "\n",
        "### To complete, you need to understand 3 things:\n",
        "\n",
        "**1) AI/main.py ‚Üí How the real system creates the backend**\n",
        "\n",
        "Find the build_lane() function to see:\n",
        "\n",
        "- It checks `LANE_MODEL`\n",
        "\n",
        "- It maps the model ‚Üí to the correct backend class (YoloV8Backend, PIDNetBackend, etc.)\n",
        "\n",
        "- It passes parameters from the configuration to the class\n",
        "\n",
        "> ‚û° This is the logic you need to recreate in the lab.\n",
        "\n",
        "**2) AI/configs/config.py ‚Üí Find model parameters**\n",
        "\n",
        "Here you will find:\n",
        "\n",
        "- `PIDNET_H`, `PIDNET_W`, `PIDNET_THR`, `PIDNET_ARCH`\n",
        "\n",
        "- `TWIN_H`, `TWIN_W`, `TWIN_THR`, `TWIN_NUM_CLASSES`\n",
        "\n",
        "- `IMGSZ`, `CONF` for YOLOv8\n",
        "\n",
        "- `BISENET_*` for BiSeNet\n",
        "\n",
        ">‚û° These are the ‚Äúmaterials‚Äù you must pass in when initializing the backend.\n",
        "\n",
        "**3) AI/LaneDetection/Lane_weight/ ‚Üí Corresponding weight file**\n",
        "\n",
        "Check this folder to find:\n",
        "\n",
        "- which weight file each model uses\n",
        "\n",
        "- the correct folder name\n",
        "\n",
        "- the correct extension (.pt or .pth).\n",
        "\n",
        ">‚û° You are accurately simulating how a real pipeline finds the weight file upon startup."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1.1. Dictionary: model name -> corresponding weight file name in the Lane_weight folder\n",
        "LANE_WEIGHT_NAME = {\n",
        "    \"yolov8\":  \"Yolo_v8/best.pt\",\n",
        "    \"pidnet\":  \"PIDNet/best.pt\",\n",
        "    \"twinlite\":\"TwinLite/best.pth\",\n",
        "    \"bisenet\": \"BiseNet/best.pth\",\n",
        "}\n",
        "\n",
        "def get_lane_weight_path(model_name: str) -> Path:\n",
        "    \"\"\"\n",
        "    Returns the full path to the weight file for model_name.\n",
        "\n",
        "    General hints:\n",
        "    - The root directory containing the weights is located in the LaneDetection/Lane_weight folder of your project.\n",
        "    - You can get the specific filename from the LANE_WEIGHT_NAME dictionary above.\n",
        "    \"\"\"\n",
        "    name = model_name.lower()\n",
        "    if name not in LANE_WEIGHT_NAME:\n",
        "        raise ValueError(f\"Unknown lane model: {model_name}\")\n",
        "\n",
        "    # TODO: Concatenate the weight folder path with the corresponding filename.\n",
        "    # You need to decide which elements to use from the C.ROOT variable.\n",
        "    weights_dir = ...   # Example: Path to the folder containing all weight files\n",
        "    weight_rel  = ...   # Example: File name of weight taken from the dictionary LANE_WEIGHT_NAME\n",
        "    weight_path = ...   # Combine folder + file name to get the full path\n",
        "\n",
        "    return weight_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_backend(model_name: str):\n",
        "    \"\"\"\n",
        "    Initialize the corresponding backend lane segmentation.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model_name : str\n",
        "        'yolov8' | 'pidnet' | 'twinlite' | 'bisenet'\n",
        "    \"\"\"\n",
        "    name = model_name.lower()\n",
        "    weights = get_lane_weight_path(name)\n",
        "\n",
        "    # TODO: Complete each if/elif branch.\n",
        "    # General suggestions:\n",
        "    # - Configuration parameters (input size, threshold, number of classes, etc.) are defined in the project's config file.\n",
        "    # - Open configs/config.py to see the names of the parameters corresponding to each model.\n",
        "    if name == \"yolov8\":\n",
        "        backend = YoloV8Backend(\n",
        "            weights=str(weights),\n",
        "            device=C.DEVICE,\n",
        "            imgsz=...,   # Hint: Input image sizes are shared across YOLO\n",
        "            conf=...,    # Hint: YOLO confidence threshold\n",
        "        )\n",
        "    elif name == \"pidnet\":\n",
        "        backend = PIDNetBackend(\n",
        "            weights=str(weights),\n",
        "            device=C.DEVICE,\n",
        "            input_h=...,   # Hint: PIDNet input height\n",
        "            input_w=...,   # Hint: PIDNet input width\n",
        "            thr=...,       # Hint: PIDNet segmentation threshold\n",
        "            arch=...,      # Suggestion: Choose PIDNet architecture\n",
        "        )\n",
        "    elif name == \"twinlite\":\n",
        "        backend = TwinLiteBackend(\n",
        "            weights=str(weights),\n",
        "            device=C.DEVICE,\n",
        "            input_h=...,          # Hint: TwinLite input height\n",
        "            input_w=...,          # Hint: TwinLite input width\n",
        "            thr=...,              # Hint: TwinLite segmentation threshold\n",
        "            num_classes=...,      # Hint: TwinLite output class number\n",
        "        )\n",
        "    elif name == \"bisenet\":\n",
        "        backend = BiseNetV2Backend(\n",
        "            weights=str(weights),\n",
        "            device=C.DEVICE,\n",
        "            input_h=...,          # Hint: input height of BiSeNetV2\n",
        "            input_w=...,          # Hint: input width of BiSeNetV2\n",
        "            num_classes=...,      # Hint: number of output classes of BiSeNetV2\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model_name: {model_name}\")\n",
        "\n",
        "    return backend\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1.2. After filling in TODO, run this cell for a quick check.\n",
        "for name in [\"yolov8\", \"pidnet\", \"twinlite\", \"bisenet\"]:\n",
        "    try:\n",
        "        b = build_backend(name)\n",
        "        print(f\"{name:8s} ->\", b.__class__.__name__)\n",
        "    except Exception as e:\n",
        "        print(f\"{name:8s} -> ERROR:\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac4df263",
      "metadata": {},
      "source": [
        "After reading the files above, you will understand that the process from model_name ‚Üí finding weights ‚Üí getting configurations ‚Üí creating backend is a standard procedure, similar to \"selecting perception modules\" in a real autonomous vehicle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load sample frames\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0636ca2c",
      "metadata": {},
      "source": [
        "### Overview\n",
        "\n",
        "Before loading images into the backend, you must ensure that the images are loaded correctly, as every subsequent step depends on the quality of the input images.\n",
        "\n",
        "This task helps you understand how the pipeline actually receives frames from the camera and processes each frame.\n",
        "\n",
        "### To complete:\n",
        "\n",
        "**1) Understand the correct frame directory structure**\n",
        "\n",
        "You must accurately identify:\n",
        "\n",
        "- Where the folder containing the frames is located\n",
        "\n",
        "- What the pattern file is (*.jpg, *.png, ‚Ä¶)\n",
        "\n",
        "- What the file name format is (Lab1_frames_01.png, frame_001.jpg‚Ä¶)\n",
        "\n",
        ">‚û° Because glob() will not find the frame if the pattern is incorrect ‚Üí number of frames = 0.\n",
        "\n",
        "**2) Use OpenCV to read the images**\n",
        "\n",
        "cv2.imread() reads the image in BGR format, which is the format required by the backend.\n",
        "\n",
        "You need to check:\n",
        "\n",
        "- whether the image loads correctly\n",
        "\n",
        "- whether the image shape is correct (H, W, 3)\n",
        "\n",
        "- Similar to a real pipeline, checking the first 1‚Äì2 frames helps ensure valid camera input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "FRAMES_DIR = ROOT / \"Lab\" / \"Lab1\" / \"Lab1_frames\"\n",
        "\n",
        "frame_paths = sorted(FRAMES_DIR.glob(\"frame_*.jpg\"))\n",
        "print(\"Number of frames found:\", len(frame_paths))\n",
        "for p in frame_paths[:5]:\n",
        "    print(\" -\", p)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View a frame\n",
        "if len(frame_paths) == 0:\n",
        "    raise RuntimeError(\"No frames found in data/lab1_frames\")\n",
        "\n",
        "sample_path = frame_paths[0]\n",
        "frame_bgr = cv2.imread(str(sample_path))\n",
        "if frame_bgr is None:\n",
        "    raise FileNotFoundError(f\"Unable to read the image: {sample_path}\")\n",
        "\n",
        "frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.imshow(frame_rgb)\n",
        "plt.title(sample_path.name)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2859447",
      "metadata": {},
      "source": [
        "After Task 2, you understand how to properly pipeline frames from the camera ‚Üí this is a fundamental step for the backend to process correctly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3.  Build a function to display frame + mask lane\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44d4e9ad",
      "metadata": {},
      "source": [
        "### Overview\n",
        "\n",
        "In a real project, the lane mask is overlaid onto the image for debugging and visualization.\n",
        "\n",
        "Overlaying helps you see:\n",
        "\n",
        "- How the model segments the lane\n",
        "\n",
        "- Whether the mask is seamless or noisy\n",
        "\n",
        "- Whether the lane matches the actual path.\n",
        "\n",
        "- The visualize function in this Task accurately simulates the overlay logic of a real pipeline in main.py or `lane_pipeline.py`.\n",
        "\n",
        "### To write the show_frame_and_mask function:\n",
        "\n",
        "**1) Convert the image to RGB**\n",
        "\n",
        "Matplotlib displays images in RGB ‚Üí you must convert from BGR to RGB.\n",
        "\n",
        "**2) Create an overlay layer**\n",
        "\n",
        "- Copy the original frame\n",
        "\n",
        "- Fill the mask area (frame[mask>0] = [255,0,0])\n",
        "\n",
        "- Choose any lane color\n",
        "\n",
        "**3) Use cv2.addWeighted**\n",
        "\n",
        "Create a transparent frame, allowing you to see both the lane and the background.\n",
        "\n",
        "Genuine pipelines use this exact technique."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3b0d1f8",
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_frame_and_mask(frame_bgr, mask01, title=\"\"):\n",
        "    \"\"\"Display the original frame and the frame with the overlay lane.\"\"\"\n",
        "    # TODO: Converting from BGR (OpenCV) to RGB (matplotlib)\n",
        "    frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # TODO: Create a copy and color the lane area (mask01 == 1)\n",
        "    overlay = frame_rgb.copy()\n",
        "    overlay[mask01 > 0] = ...   # Hint: Use a striking color like pure red\n",
        "\n",
        "    # TODO: Mix frame_rgb and overlay using addWeighted to create a transparent effect.\n",
        "    alpha = 0.5\n",
        "    blended = cv2.addWeighted(frame_rgb, 1 - alpha, overlay, alpha, 0)\n",
        "\n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(frame_rgb)\n",
        "    plt.title(\" Original frame\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(blended)\n",
        "    plt.title(title)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "151b6b01",
      "metadata": {},
      "source": [
        "You understand the visualization mechanism of pipeline lane detection and know how to overlay masks correctly, just like in a real project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. Test run a backend (TwinliteNet)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c61d5eed",
      "metadata": {},
      "source": [
        "### Overview\n",
        "\n",
        "Each backend has a different infer method: resizing input, normalizing, changing the order of color channels.\n",
        "\n",
        "However, the backend class has \"wrapped\" everything into one function:\n",
        "\n",
        "`backend.infer_mask01(frame_bgr)`\n",
        "\n",
        "The actual pipeline only calls this function.\n",
        "\n",
        "Task 4 helps you see how a backend works independently.\n",
        "\n",
        "### To complete this task you need:\n",
        "\n",
        "**1) Identify the infer function in the backend file**\n",
        "\n",
        "Examples:\n",
        "\n",
        "- YOLOv8: infer_mask01()\n",
        "\n",
        "- PIDNet: infer_mask01()\n",
        "\n",
        "- TwinLite: infer_mask01()\n",
        "\n",
        "- BiSeNet: infer_mask01()\n",
        "\n",
        "They all return a mask.\n",
        "\n",
        "**2) See the required input**\n",
        "\n",
        "Backends usually receive the original image BGR (resized inside the class).\n",
        "\n",
        "**3) View the output mask**\n",
        "\n",
        "The output can be:\n",
        "\n",
        "- 0‚Äì255\n",
        "\n",
        "- or 0‚Äì1\n",
        "\n",
        "But you should always cast it to 0‚Äì1 in the lab for consistency:\n",
        "\n",
        "`(mask > 0).astype(np.uint8)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "backend = build_backend(\"twinlite\") # üîÅ Change the model name if you want to use a different bankend (Yolov8, BiseNet, PidNet)\n",
        "\n",
        "sample_path = frame_paths[0]\n",
        "frame_bgr = cv2.imread(str(sample_path))\n",
        "\n",
        "# TODO: Call the backend's infer function to get the lane segment mask.\n",
        "mask = ...      # Hint: Use a backend method with the input frame_bgr\n",
        "\n",
        "# TODO: Convert mask to mask01 in 0/1 format (True/False -> 1/0)\n",
        "mask01 = ...    \n",
        "\n",
        "print(\"Frame shape:\", frame_bgr.shape)\n",
        "print(\"Mask  shape:\", getattr(mask, \"shape\", None))\n",
        "\n",
        "show_frame_and_mask(frame_bgr, mask01, title=\"twinlite ‚Äì mask01\") # üîÅ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfad41de",
      "metadata": {},
      "source": [
        "You understand that the backend is the ‚Äúperception black box‚Äù: just input the image ‚Üí remove the mask.\n",
        "This is the exact logic that a real pipeline uses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. Comparing 4 backends on the same frame\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19d5052b",
      "metadata": {},
      "source": [
        "### Overview\n",
        "\n",
        "This task simulates a real-world model benchmarking problem:\n",
        "- Using the same frame ‚Üí running through 4 different models ‚Üí comparing quality and stability.\n",
        "\n",
        "- The research team's actual pipeline is usually exactly the same.\n",
        "\n",
        "### To complete:\n",
        "\n",
        "**1) Reuse code from Task 3 & Task 4**\n",
        "\n",
        "- Task 3: reuse the overlay function\n",
        "\n",
        "- Task 4: use build_backend(name) and infer_mask01(...)\n",
        "\n",
        "**2) Loop through the list of models**\n",
        "\n",
        "[\"yolov8\", \"pidnet\", \"twinlite\", \"bisenet\"]\n",
        "\n",
        "**3) Visualize each backend**\n",
        "\n",
        "Give clear titles: YOLOv8 / PIDNet / TwinLite / BiSeNet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_names = [\"yolov8\", \"pidnet\", \"twinlite\", \"bisenet\"]\n",
        "\n",
        "sample_path = frame_paths[0]\n",
        "frame_bgr = cv2.imread(str(sample_path))\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "for i, name in enumerate(model_names, start=1):\n",
        "    # TODO: initialize the corresponding backend.\n",
        "    backend = ...\n",
        "\n",
        "    # TODO: Infer mask and switch to mask01 0/1\n",
        "    mask = ...\n",
        "    mask01 = ...\n",
        "\n",
        "    # TODO: Create an overlay from mask01 (the logic can be reused in Task 3)\n",
        "    frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
        "    overlay = frame_rgb.copy()\n",
        "    overlay[mask01 > 0] = [255, 0, 0]\n",
        "    blended = cv2.addWeighted(frame_rgb, 0.5, overlay, 0.5, 0)\n",
        "\n",
        "    plt.subplot(2, 2, i)\n",
        "    plt.imshow(blended)\n",
        "    plt.title(name.upper())\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa053678",
      "metadata": {},
      "source": [
        "You understand the strengths and weaknesses of each model and see why the pipeline of an autonomous vehicle needs a strong backend."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6. Create and store binary lane masks for analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fe0525a",
      "metadata": {},
      "source": [
        "### Overview\n",
        "\n",
        "In the entire project's pipeline lane-keeping, mask01 (binary mask) is a required input for the following steps:\n",
        "\n",
        "- ROI selection\n",
        "\n",
        "- Morphology\n",
        "\n",
        "- BEV transform\n",
        "\n",
        "- Lane geometry estimation\n",
        "\n",
        "- Controller (EMA + steering output)\n",
        "\n",
        "Task 6 helps you create a standard mask01 set to reuse exactly like the real pipeline.\n",
        "\n",
        "### To complete this Task:\n",
        "\n",
        "**1) Loop through all frames**\n",
        "\n",
        "Infer mask ‚Üí cast to 0‚Äì1 ‚Üí save to list.\n",
        "\n",
        "**2) Stack into a numpy array**\n",
        "\n",
        "`all_masks = np.stack(all_masks, axis=0)`\n",
        "\n",
        "The shape will be: `(10, H, W)`\n",
        "\n",
        "3) Save using numpy\n",
        "\n",
        "For .py files:\n",
        "\n",
        "`np.save(\"lab1_mask01.npy\", all_masks)`\n",
        "\n",
        "Or PNG (your version)\n",
        "\n",
        "- mask01 ‚Üí 0‚Äì1\n",
        "\n",
        "- multiply 255 ‚Üí PNG\n",
        "\n",
        "- save each file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# MODEL_FOR_LAB2 = \"twinlite\"  # or 'pidnet' / 'yolov8' / 'bisenet'\n",
        "MODEL_FOR_LAB2 = \"twinlite\" #üîÅ select bankend (Yolov8, BiseNet, PidNet)\n",
        "\n",
        "backend = build_backend(MODEL_FOR_LAB2)\n",
        "\n",
        "# TODO: Create a folder to save the PNG output.\n",
        "OUT_DIR = ROOT / \"Lab\" / \"Lab1\" / \"Lab1_masks\"\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "for i, p in enumerate(frame_paths, start=1):\n",
        "    frame_bgr = cv2.imread(str(p))\n",
        "    if frame_bgr is None:\n",
        "        raise FileNotFoundError(f\"Unable to read the image: {p}\")\n",
        "\n",
        "    # TODO: Infer mask from backend\n",
        "    mask = ...\n",
        "\n",
        "    # TODO: Convert mask to binary 0‚Äì1 (uint8)\n",
        "    mask01 = ...\n",
        "\n",
        "    # TODO: Multiply by 255 to save the PNG image (0‚Äì1 ‚Üí 0‚Äì255)\n",
        "    mask_png = ...\n",
        "\n",
        "    out_path = OUT_DIR / f\"Lab1_mask01_{i:02d}.png\"\n",
        "\n",
        "    cv2.imwrite(str(out_path), mask_png)\n",
        "\n",
        "print(\"‚û° I've finished generating the PNG mask for 10 frames!\", out_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe913991",
      "metadata": {},
      "source": [
        "You have completed the perception part of the pipeline lane detection.\n",
        "From here, Lab 2 & Lab 3 will use this mask to build ROI ‚Üí BEV ‚Üí Control as in the real project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 7. Summary\n",
        "\n",
        "Upon completing all the TODOs, you will have:\n",
        "\n",
        "- Initialized the backend corresponding to each model by reading and understanding the project's configuration file.\n",
        "\n",
        "- Used the backend's infer function to create a binary lane mask.\n",
        "\n",
        "- Visually compared four backends on the same frame.\n",
        "\n",
        "- Generated the `Lab1_mask01_*.png` file for Lab 2.\n",
        "\n",
        "üëâ Don't forget to save the `.png` files in the `/Lab/Lab1_mask/Lab1_mask01_01.png ... Lab1_mask01_10` directory."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3444ecc5",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
