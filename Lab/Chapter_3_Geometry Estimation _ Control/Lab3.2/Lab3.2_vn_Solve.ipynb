{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57ae5c4d",
   "metadata": {},
   "source": [
    "# Lab 3.2 — Pipeline giữ làn hoàn chỉnh (Perception → Geometry → Control → Overlay)\n",
    "\n",
    "Lab này tích hợp toàn bộ các thành phần đã được xây dựng trong các lab trước:\n",
    "\n",
    "#### Từ Lab 1 (Perception)\n",
    "- Trích xuất mặt nạ làn bằng deep learning (YOLO / PIDNet / TwinLite / BiSeNet)\n",
    "\n",
    "#### Từ Lab 2 (Geometry)\n",
    "- Lọc ROI\n",
    "- Tinh chỉnh hình thái học\n",
    "- Chiếu Bird’s-Eye View (BEV)\n",
    "\n",
    "#### Từ Lab 3.1 (Lane Geometry)\n",
    "- center_x() để phát hiện tâm làn\n",
    "- heading_deg_at_ratio() từ hai điểm lấy mẫu theo phương dọc\n",
    "- meters_per_pixel() để chuyển px → mét\n",
    "- Lấy mẫu đa tỉ lệ (r = 0.98, 0.92, 0.82, 0.72)\n",
    "- Chọn tỉ lệ thích ứng dựa trên độ ổn định\n",
    "\n",
    "### Trong Lab này bạn sẽ:\n",
    "1. Triển khai bộ điều khiển đánh lái đơn giản.\n",
    "2. Chuyển hình học làn → LEFT / RIGHT / STRAIGHT.\n",
    "3. Vẽ overlay thời gian thực lên các khung hình video.\n",
    "4. Chạy toàn bộ pipeline giữ làn trên một video đầu vào thực tế.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea4b40f",
   "metadata": {},
   "source": [
    "### Environment Setup\n",
    "\n",
    "Lab này yêu cầu nhiều thư viện xử lý ảnh và tính toán số.\n",
    "Chúng ta sẽ cài đặt và kiểm tra tất cả các dependencies trước khi chạy pipeline\n",
    "hình học và điều khiển.\n",
    "\n",
    "**Required Libraries**\n",
    "- **numpy** — thao tác ma trận  \n",
    "- **opencv-python** — xử lý ảnh/video  \n",
    "- **matplotlib** — trực quan hóa  \n",
    "- **torch** — tải các mô hình lane deep learning  \n",
    "- **ultralytics** (tùy chọn) — các mô hình YOLO cho lane/segmentation  \n",
    "\n",
    "Hãy đảm bảo môi trường runtime có GPU nếu bạn muốn chạy backend deep learning.\n",
    "Chế độ CPU-only vẫn chấp nhận được cho lab này.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fd1063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All dependencies installed successfully.\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy opencv-python matplotlib ultralytics --quiet\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 --quiet\n",
    "\n",
    "print(\"All dependencies installed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acef3a22",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "\n",
    "Chúng ta import tất cả các thư viện tiêu chuẩn được sử dụng trong suốt lab:\n",
    "\n",
    "- numpy cho tính toán số  \n",
    "- cv2 cho xử lý ảnh  \n",
    "- matplotlib cho trực quan hóa  \n",
    "- Tùy chọn: torch + ultralytics cho backend segmentation  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0116dfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed702cb",
   "metadata": {},
   "source": [
    "### Version Check\n",
    "\n",
    "Cần xác nhận rằng:\n",
    "- OpenCV đã được cài đặt đúng  \n",
    "- Torch nhận diện được CUDA (tùy chọn)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9657bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"OpenCV version:\", cv2.__version__)\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f4de40",
   "metadata": {},
   "source": [
    "### 1. Perception Module: YOLOv8 Backend\n",
    "\n",
    "> **Note:** Module này đã được triển khai đầy đủ trong **Lab 1**. Trong Lab 3, chúng ta xem nó như một **cảm biến \"Black Box\"** cung cấp mặt nạ làn đường nhị phân.\n",
    "\n",
    "Chúng ta sử dụng class `YoloV8Backend` để:\n",
    "1.  Tải trọng số đã huấn luyện (`best.pt`).\n",
    "2.  Thực hiện suy luận trên từng khung hình video.\n",
    "3.  Trả về mặt nạ phân đoạn nhị phân (`0` cho nền, `1` cho làn đường).\n",
    "\n",
    "**Action:** Chỉ cần **chạy cell bên dưới** để khởi tạo backend. Không cần viết code tại đây.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262586b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloV8Backend:\n",
    "    \"\"\"\n",
    "    Lightweight wrapper for YOLOv8 segmentation → binary lane mask.\n",
    "    Matches real project structure but simplified for lab environment.\n",
    "    \"\"\"\n",
    "    def __init__(self, weights, device=\"cuda\", imgsz=640, conf=0.18):\n",
    "        self.model = YOLO(weights)\n",
    "        self.device = device\n",
    "        self.imgsz = imgsz\n",
    "        self.conf = conf\n",
    "        self.fp16 = (torch.cuda.is_available() and device != \"cpu\")\n",
    "        self.model.to(device)\n",
    "        self.model.fuse()\n",
    "\n",
    "    def infer_mask01(self, frame_bgr):\n",
    "        H, W = frame_bgr.shape[:2]\n",
    "        res = self.model.predict(frame_bgr, imgsz=self.imgsz, conf=self.conf,\n",
    "                                 device=self.device, verbose=False, half=self.fp16)\n",
    "        r0 = res[0]\n",
    "        if r0.masks is None:\n",
    "            return np.zeros((H, W), np.uint8)\n",
    "\n",
    "        mk = r0.masks.data.cpu().numpy().astype(np.uint8)\n",
    "        merged = np.zeros((H, W), np.uint8)\n",
    "        for k in range(mk.shape[0]):\n",
    "            merged = cv2.bitwise_or(merged, cv2.resize(mk[k], (W, H)))\n",
    "\n",
    "        return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465b75cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = YoloV8Backend(r\"C:\\Users\\admin\\ACE_Finalv4\\AI\\LaneDetection\\Lane_weight\\Yolo_v8\\best.pt\")\n",
    "print(\"Backend loaded:\", backend.name() if hasattr(backend, \"name\") else \"YOLOv8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b6f28d",
   "metadata": {},
   "source": [
    "### 2. Preprocessing Module: ROI & BEV (Recap from Lab 2)\n",
    "\n",
    "**Context:** Trong **Lab 2**, chúng ta đã xây dựng một pipeline tiền xử lý mạnh mẽ để làm sạch mặt nạ phân đoạn và biến đổi nó thành Bird's-Eye-View (BEV). Chúng ta sẽ tái sử dụng các tiện ích này tại đây.\n",
    "\n",
    "Module này bao gồm:\n",
    "1. **apply_roi**: Cắt vùng quan tâm (loại bỏ bầu trời/phần nền).\n",
    "2. **refine_mask01**: Áp dụng các phép toán hình thái học (Opening/Closing) để giảm nhiễu và lấp đầy khe hở.\n",
    "3. **BEVProjector**: Một class quản lý ma trận Homography để warp ảnh từ *Perspective View* sang *Top-Down View*.\n",
    "\n",
    "**Action:** Chạy cell bên dưới để định nghĩa các hàm hỗ trợ này.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34cb66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_roi(mask, poly):\n",
    "    H, W = mask.shape\n",
    "    pts = np.array([(int(x*W), int(y*H)) for x,y in poly], dtype=np.int32)\n",
    "    roi = np.zeros_like(mask)\n",
    "    cv2.fillPoly(roi, [pts], 1)\n",
    "    return mask * roi\n",
    "\n",
    "def refine_mask01(mask):\n",
    "    k = np.ones((5,5), np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, k)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, k)\n",
    "    return mask\n",
    "\n",
    "class BEVProjector:\n",
    "    def __init__(self):\n",
    "        self.src = ((0.20, 0.58),(0.10, 0.90),(0.90, 0.90),(0.80, 0.58))\n",
    "        self.dst = ((0.25, 0.00),(0.25, 1.00),(0.75, 1.00),(0.75, 0.00))\n",
    "        self.M = None\n",
    "        self.M_inv = None\n",
    "        self._wh = None\n",
    "\n",
    "    def _ensure(self, W, H):\n",
    "        if self._wh == (W,H): return\n",
    "        src = np.float32([(x*W,y*H) for x,y in self.src])\n",
    "        dst = np.float32([(x*W,y*H) for x,y in self.dst])\n",
    "        self.M = cv2.getPerspectiveTransform(src, dst)\n",
    "        self.M_inv = cv2.getPerspectiveTransform(dst, src)\n",
    "        self._wh = (W,H)\n",
    "\n",
    "    def warp(self, mask):\n",
    "        H,W = mask.shape\n",
    "        self._ensure(W,H)\n",
    "        bev = cv2.warpPerspective(mask*255, self.M, (W,H), cv2.INTER_NEAREST)\n",
    "        return (bev>0).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f64dad",
   "metadata": {},
   "source": [
    "### Geometry Math ( Recap from Lab 3.1)\n",
    "\n",
    "Trong phần này, chúng ta định nghĩa lại toàn bộ các hàm lane-geometry cần thiết cho pipeline hoàn chỉnh.  \n",
    "Mặc dù các hàm này đã được triển khai trong Lab 3.1, Jupyter notebooks yêu cầu phải khai báo lại chúng trong Lab 3.2.\n",
    "\n",
    "Khối này cung cấp:\n",
    "- center_x() — trích tâm làn tại một tỉ lệ BEV cho trước  \n",
    "- heading_deg_at_ratio() — tính góc hướng bằng hai điểm lấy mẫu theo chiều dọc  \n",
    "- multi_ratio_measure() — đánh giá nhiều tỉ lệ (0.98, 0.92, 0.82, 0.72)  \n",
    "- adaptive_select_solution() — chọn tỉ lệ có ước lượng hình học ổn định nhất  \n",
    "\n",
    "Các hàm này chuyển BEV mask đã tinh chỉnh thành các đại lượng hình học thực-valued được sử dụng bởi controller.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3e8347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_x(bev, r):\n",
    "    H, W = bev.shape\n",
    "    y = int(r * H)\n",
    "    xs = np.where(bev[y] > 0)[0]\n",
    "    if len(xs) < 2:\n",
    "        return np.nan\n",
    "    return 0.5 * (xs[0] + xs[-1])\n",
    "\n",
    "def heading_deg_at_ratio(bev, r, dy=30):\n",
    "    H, W = bev.shape\n",
    "    y = int(r * H)\n",
    "    y2 = max(0, y - dy)\n",
    "\n",
    "    xs1 = np.where(bev[y] > 0)[0]\n",
    "    xs2 = np.where(bev[y2] > 0)[0]\n",
    "\n",
    "    if len(xs1)<2 or len(xs2)<2:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    cx1 = 0.5*(xs1[0]+xs1[-1])\n",
    "    cx2 = 0.5*(xs2[0]+xs2[-1])\n",
    "    dx = cx1 - cx2\n",
    "    dy = (y - y2)\n",
    "\n",
    "    ang = np.degrees(np.arctan2(dx, dy + 1e-6))\n",
    "    return ang, cx1\n",
    "\n",
    "def multi_ratio_measure(bev, ratios, dy_px=30, lane_width_m=0.20):\n",
    "    H, W = bev.shape\n",
    "    mpp = lane_width_m / 20.0  \n",
    "\n",
    "    centers, pos_list, head_list = [], [], []\n",
    "    for r in ratios:\n",
    "        head, cx = heading_deg_at_ratio(bev, r, dy_px)\n",
    "        pos_m = (W/2 - cx) * mpp\n",
    "        centers.append(cx)\n",
    "        pos_list.append(pos_m)\n",
    "        head_list.append(head)\n",
    "\n",
    "    return centers, pos_list, head_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cb777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_select(centers, pos_list, head_list, ratios,\n",
    "                             W_STAB=2.0, W_HEAD=0.1, W_LAT=0.05):\n",
    "    best_i = 0\n",
    "    best_score = -1e9\n",
    "\n",
    "    for i,r in enumerate(ratios):\n",
    "        cx = centers[i]\n",
    "        if np.isnan(cx): continue\n",
    "\n",
    "        std_pos = abs(pos_list[i])\n",
    "        mean_head = abs(head_list[i])\n",
    "        score = (W_STAB/(std_pos+1e-6) - W_HEAD*mean_head - W_LAT*(1-r))\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_i = i\n",
    "\n",
    "    return {\n",
    "        \"best_ratio\": ratios[best_i],\n",
    "        \"pos\": pos_list[best_i],\n",
    "        \"head\": head_list[best_i]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e0c12e",
   "metadata": {},
   "source": [
    "### Controller\n",
    "\n",
    "Controller chuyển hình học làn đường thành lệnh đánh lái để giữ xe ở giữa làn.  \n",
    "Nó kết hợp hai loại thông tin hình học:\n",
    "\n",
    "1. **Lateral offset** (pos_m):  \n",
    "   Độ lệch ngang của xe so với tâm làn (tính theo mét).  \n",
    "   - Nếu pos_m > 0 → xe lệch sang PHẢI → phải đánh lái SANG TRÁI  \n",
    "   - Nếu pos_m < 0 → xe lệch sang TRÁI → phải đánh lái SANG PHẢI  \n",
    "\n",
    "2. **Heading angle** (head_deg):  \n",
    "   Góc hướng của làn so với hướng tiến của xe.  \n",
    "   - Góc dương → làn cong sang trái  \n",
    "   - Góc âm → làn cong sang phải  \n",
    "\n",
    "Để hiệu chỉnh quỹ đạo xe, ta dùng một công thức điều khiển tuyến tính kết hợp hai tín hiệu này:\n",
    "\n",
    "#### **Control law**\n",
    "\n",
    "$$\n",
    "\\text{steer} = k_{\\text{pos}} \\cdot \\text{pos}_m \\;+\\; k_{\\text{head}} \\cdot \\text{head}_{deg}\n",
    "$$\n",
    "\n",
    "#### Ý nghĩa từng thành phần:\n",
    "\n",
    "- $( k_{\\text{pos}} \\cdot \\text{pos}_m $):  \n",
    "  Sửa sai lệch vị trí so với tâm làn → **đóng góp chính vào đánh lái**.\n",
    "\n",
    "- $( k_{\\text{head}} \\cdot \\text{head}_{deg} $):  \n",
    "  Dự đoán độ cong của làn để hiệu chỉnh sớm hơn → **ổn định khi vào cua**.\n",
    "\n",
    "Các hệ số:\n",
    "- $( k_{\\text{pos}} $): mức độ controller phản ứng với độ lệch ngang  \n",
    "- $( k_{\\text{head}} $): mức độ phản ứng với độ cong làn  \n",
    "\n",
    "Các giá trị này quyết định độ “gắt” hay “mượt” của đánh lái.\n",
    "\n",
    "Đầu ra đánh lái cuối cùng bị ràng buộc trong giới hạn phần cứng:\n",
    "\n",
    "$$\n",
    "\\text{steer} \\in [-50, 50]\n",
    "$$\n",
    "\n",
    "#### Nhãn đánh lái (phục vụ trực quan hóa)\n",
    "\n",
    "Để dễ diễn giải giá trị đánh lái, ta chuyển nó thành ba nhãn:\n",
    "\n",
    "- **LEFT** → steer > threshold  \n",
    "- **RIGHT** → steer < −threshold  \n",
    "- **STRAIGHT** → giá trị nhỏ, xem như không có đổi hướng đáng kể  \n",
    "\n",
    "Phân loại này chỉ phục vụ hiển thị, không ảnh hưởng đến điều khiển.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e1ce6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def controller(pos_m, head_deg, k_pos=40.0, k_head=1.5):\n",
    "    steer = k_pos * pos_m + k_head * head_deg\n",
    "    steer = np.clip(steer, -50, 50)\n",
    "    return float(steer)\n",
    "\n",
    "def steering_label(steer, thresh=3.0):\n",
    "    if steer > thresh:\n",
    "        return \"LEFT\"\n",
    "    elif steer < -thresh:\n",
    "        return \"RIGHT\"\n",
    "    else:\n",
    "        return \"STRAIGHT\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8d7e74",
   "metadata": {},
   "source": [
    "### Draw Overlay\n",
    "\n",
    "Hàm này trực quan hóa toàn bộ đầu ra hình học của làn đường lên trên khung hình camera gốc.  \n",
    "Nó cung cấp cách nhìn trực quan giúp hiểu pipeline đang xử lý gì ở từng bước.\n",
    "\n",
    "Overlay bao gồm:\n",
    "\n",
    "#### **1. BEV Mask Projected Back to Camera View**\n",
    "Mặt nạ BEV nhị phân (top-down view) được inverse-warp bằng homography nghịch $( M^{-1} $)  \n",
    "để vùng làn đường có thể chạy được hiển thị lại trên ảnh camera.  \n",
    "Điều này giúp kiểm tra xem phép biến đổi BEV và tinh chỉnh mask có chính xác không.\n",
    "\n",
    "#### **2. Multi-Ratio Lane Centers**\n",
    "Với mỗi tỉ lệ lấy mẫu (ví dụ 0.98 → 0.92 → 0.82 → 0.72):\n",
    "\n",
    "- Điểm tâm làn được phát hiện trong tọa độ BEV được ánh xạ ngược sang tọa độ camera.\n",
    "- Tất cả các điểm tỉ lệ được vẽ:\n",
    "  - **Primary ratio** (tỉ lệ có điểm ổn định cao nhất) → chấm ĐỎ  \n",
    "  - **Các tỉ lệ hợp lệ khác** → chấm VÀNG  \n",
    "\n",
    "Điều này giúp quan sát:\n",
    "- liệu phát hiện tâm làn có ổn định giữa các tỉ lệ không  \n",
    "- liệu cơ chế adaptive ratio selection có hoạt động đúng không  \n",
    "\n",
    "#### **3. On-Screen Debug Information**\n",
    "Một bảng thông tin nhỏ được vẽ ở góc trên bên trái hiển thị:\n",
    "\n",
    "- Lateral offset theo mét  \n",
    "- Heading angle theo độ  \n",
    "- Nhãn điều khiển đánh lái (“LEFT”, “RIGHT”, “STRAIGHT”)  \n",
    "\n",
    "Các giá trị này giúp liên hệ overlay trực quan với đầu ra hình học và controller.\n",
    "\n",
    "#### **Purpose**\n",
    "Bước trực quan hóa này rất quan trọng cho việc debug:\n",
    "- lỗi segmentation  \n",
    "- sai lệch BEV  \n",
    "- bất ổn hình học  \n",
    "- lỗi chọn tỉ lệ  \n",
    "- hành vi controller  \n",
    "\n",
    "Hàm trả về một frame đã được annotate để hiển thị hoặc lưu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529f75d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_overlay(frame_bgr, bev01, M_inv, ratios, centers_px, primary_idx, pos_m, head_deg, dir_label):\n",
    "    draw = frame_bgr.copy()\n",
    "    H, W = draw.shape[:2]\n",
    "    # ============================\n",
    "    # (1) Warp BEV mask về camera\n",
    "    # ============================\n",
    "    if bev01 is not None and M_inv is not None:\n",
    "        bev_warp = cv2.warpPerspective(\n",
    "            (bev01 * 255).astype(np.uint8),\n",
    "            M_inv, (W, H),\n",
    "            flags=cv2.INTER_NEAREST\n",
    "        )\n",
    "        green = np.zeros_like(draw)\n",
    "        green[bev_warp > 0] = (0, 180, 0)\n",
    "        draw = cv2.addWeighted(draw, 1.0, green, 0.8, 0)\n",
    "\n",
    "    # ============================\n",
    "    # (2) Chuyển điểm BEV → camera\n",
    "    # ============================\n",
    "    pts_bev = []\n",
    "    for r, cx in zip(ratios, centers_px):\n",
    "        if np.isnan(cx):\n",
    "            pts_bev.append([np.nan, np.nan])\n",
    "        else:\n",
    "            y_bev = r * bev01.shape[0]\n",
    "            pts_bev.append([cx, y_bev])\n",
    "\n",
    "    valid_pts = np.array(\n",
    "        [[px, py] for px, py in pts_bev if not np.isnan(px)],\n",
    "        dtype=np.float32\n",
    "    ).reshape(-1, 1, 2)\n",
    "\n",
    "    if valid_pts.shape[0] > 0:\n",
    "        pts_cam = cv2.perspectiveTransform(valid_pts, M_inv)\n",
    "    else:\n",
    "        pts_cam = []\n",
    "\n",
    "    # ============================\n",
    "    # (3) Vẽ các điểm ratio\n",
    "    # ============================\n",
    "    cam_i = 0\n",
    "    for i, (r, cx) in enumerate(zip(ratios, centers_px)):\n",
    "        if np.isnan(cx):\n",
    "            continue\n",
    "        px, py = pts_cam[cam_i][0]\n",
    "        cam_i += 1\n",
    "        if i == primary_idx:\n",
    "            cv2.circle(draw, (int(px), int(py)), 5, (0,0,255), -1)   # đỏ\n",
    "        else:\n",
    "            cv2.circle(draw, (int(px), int(py)), 3, (0,255,255), -1) # vàng\n",
    "\n",
    "    # ============================\n",
    "    # (4) Ô thông góc, hướng\n",
    "    # ============================\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(draw, f\"Pos: {pos_m:+.3f} m\", (15,20), font, 0.45, (0,255,255), 2)\n",
    "    cv2.putText(draw, f\"Head: {head_deg:+.2f} deg\", (15,40), font, 0.55, (0,255,255), 2)\n",
    "    color_dir = (0,255,0) if dir_label==\"STRAIGHT\" else (0,0,255)\n",
    "    cv2.putText(draw, f\"DIR: {dir_label}\", (15,60), font, 0.65, color_dir, 2)\n",
    "    return draw\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d2eb15",
   "metadata": {},
   "source": [
    "### Full Pipeline Execution (Video Processing)\n",
    "\n",
    "Trong nhiệm vụ cuối cùng này, bạn sẽ chạy **toàn bộ pipeline giữ làn** trên một video lái xe đã ghi sẵn.\n",
    "Nội dung này tích hợp toàn bộ các module đã phát triển trong các lab trước:\n",
    "\n",
    "- **Perception (Lab 1):** trích xuất mặt nạ làn  \n",
    "- **Geometry (Lab 2):** ROI → tinh chỉnh → chiếu BEV  \n",
    "- **Lane estimation (Lab 3.1):** multi-ratio sampling + adaptive selection  \n",
    "- **Control (Lab 3.2):** vị trí ngang + heading → lệnh đánh lái  \n",
    "- **Visualization:** hiển thị BEV, điểm lấy mẫu và thông tin steering  \n",
    "\n",
    "Vòng lặp dưới đây thực hiện tất cả các bước trên theo từng frame:\n",
    "\n",
    "1. Tải video từ đĩa  \n",
    "2. Áp dụng segmentation và làm sạch ROI  \n",
    "3. Chiếu mặt nạ sang BEV  \n",
    "4. Tính toán hình học tại nhiều tỉ lệ  \n",
    "5. Chọn tỉ lệ ổn định nhất  \n",
    "6. Sinh lệnh đánh lái  \n",
    "7. Vẽ overlay phục vụ debug  \n",
    "8. Lưu các frame đã xử lý thành một video đầu ra\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15494f7",
   "metadata": {},
   "source": [
    "### Step 1 — Load Input Video\n",
    "\n",
    "Trong bước này, chúng ta chỉ định đường dẫn đến video lái xe sẽ được xử lý bởi toàn bộ pipeline giữ làn.  \n",
    "Cell này bao gồm:\n",
    "\n",
    "- một `video_path` cho phép người dùng chỉnh sửa  \n",
    "- kiểm tra tự động sự tồn tại của file  \n",
    "- yêu cầu nhập lại đường dẫn nếu file không tồn tại  \n",
    "- khởi tạo đối tượng đọc video của OpenCV  \n",
    "\n",
    "Điều này đảm bảo pipeline luôn bắt đầu với một video đầu vào hợp lệ và cung cấp phản hồi rõ ràng cho người học.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b0c2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = r\"C:\\Users\\admin\\ACE_images\\esp32_capture.mp4\"\n",
    "# Optional fallback if file is missing\n",
    "if not os.path.exists(video_path):\n",
    "    print(f\"[INFO] The path '{video_path}' does not exist.\")\n",
    "    print(\"Please enter a valid video file path:\")\n",
    "    video_path = input(\"Video path: \").strip()\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    raise FileNotFoundError(f\"Could not open video: {video_path}\")\n",
    "\n",
    "print(f\"[OK] Loaded input video: {video_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe02f29",
   "metadata": {},
   "source": [
    "### Step 2 — Configure Output Video Writer\n",
    "\n",
    "Ở bước này, chúng ta cấu hình video writer để lưu các frame đã được pipeline xử lý.\n",
    "\n",
    "Cell này thực hiện:\n",
    "- lấy độ phân giải và FPS từ video đầu vào  \n",
    "- tạo writer MP4 bằng OpenCV  \n",
    "- hiển thị thông tin xác nhận về vị trí lưu và tham số video  \n",
    "\n",
    "Các frame trực quan hóa sau xử lý sẽ được ghi vào `lab3_output.mp4`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb74107",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps_in       = cap.get(cv2.CAP_PROP_FPS) or 30\n",
    "\n",
    "output_path = \"lab3_output.mp4\"\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out = cv2.VideoWriter(\n",
    "    output_path,\n",
    "    fourcc,\n",
    "    fps_in,\n",
    "    (frame_width, frame_height)\n",
    ")\n",
    "\n",
    "print(f\"[OK] Output will be saved to: {output_path}\")\n",
    "print(f\"[INFO] Resolution: {frame_width}x{frame_height}, FPS: {fps_in}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5536e6ba",
   "metadata": {},
   "source": [
    "### Step 3 — Run the Full Lane-Keeping Pipeline\n",
    "\n",
    "Cell này tích hợp toàn bộ các thành phần đã được xây dựng trong các lab trước và chạy chúng theo từng frame trên video đầu vào.\n",
    "\n",
    "Pipeline bao gồm:\n",
    "\n",
    "1. ***Segmentation (Lab 1)***  \n",
    "   Sinh mặt nạ làn từ mỗi frame đầu vào và tinh chỉnh bằng ROI + morphology.\n",
    "\n",
    "2. ***BEV Projection (Lab 2)***  \n",
    "   Chuyển mặt nạ làn sang biểu diễn bird’s-eye-view để trích xuất hình học dễ dàng hơn.\n",
    "\n",
    "3. ***Multi-Ratio Geometry Sampling (Lab 3.1)***  \n",
    "   Ước lượng tâm làn và heading tại nhiều tỉ lệ lấy mẫu theo chiều dọc.\n",
    "\n",
    "4. ***Adaptive Ratio Selection (Lab 3.1)***  \n",
    "   Tự động chọn hình học ổn định nhất trong các tỉ lệ đã lấy mẫu.\n",
    "\n",
    "5. ***Controller Computation (Lab 3.2)***  \n",
    "   Chuyển hình học làn thành lệnh đánh lái và nhãn hướng lái.\n",
    "\n",
    "6. ***Visualization Overlay***  \n",
    "   Vẽ BEV, các điểm tỉ lệ và thông tin debug steering lên frame.\n",
    "\n",
    "7. ***Video Export***  \n",
    "   Ghi frame đã xử lý vào video đầu ra.\n",
    "\n",
    "Khi vòng lặp kết thúc, video đã xử lý cuối cùng được lưu thành `lab3_output.mp4`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f07de22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# Lane-Keeping Full Pipeline (End-to-End)\n",
    "# ======================================================\n",
    "\n",
    "proj = BEVProjector()\n",
    "ratios = [0.98, 0.92, 0.82, 0.72]\n",
    "ROI = np.float32([[0.03,0.58],[0.97,0.58],[0.97,0.99],[0.03,0.99]])\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # (1) Segmentation + ROI refinement\n",
    "    # --------------------------------------------------\n",
    "    mask = backend.infer_mask01(frame)\n",
    "    mask = apply_roi(mask, ROI)\n",
    "    mask = refine_mask01(mask)\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # (2) BEV projection\n",
    "    # --------------------------------------------------\n",
    "    bev = proj.warp(mask)\n",
    "    bev01 = bev   # alias\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # (3) Multi-ratio geometry sampling\n",
    "    # --------------------------------------------------\n",
    "    centers, pos_list, head_list = multi_ratio_measure(bev, ratios)\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # (4) Adaptive ratio selection\n",
    "    # --------------------------------------------------\n",
    "    sel = adaptive_select(centers, pos_list, head_list, ratios)\n",
    "    pos    = sel[\"pos\"]\n",
    "    head   = sel[\"head\"]\n",
    "    r_star = sel[\"best_ratio\"]\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # (5) Steering computation\n",
    "    # --------------------------------------------------\n",
    "    steer = controller(pos, head)\n",
    "    label = steering_label(steer)\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # (6) Ratio → pixel conversion for visualization\n",
    "    # --------------------------------------------------\n",
    "    H = bev.shape[0]\n",
    "    cy = int(r_star * H)\n",
    "    cx = center_x(bev, r_star)\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # (7) Overlay visualization\n",
    "    # --------------------------------------------------\n",
    "    overlay = draw_overlay(\n",
    "        frame_bgr   = frame,\n",
    "        bev01       = bev,\n",
    "        M_inv       = proj.M_inv,\n",
    "        ratios      = ratios,\n",
    "        centers_px  = centers,\n",
    "        primary_idx = ratios.index(r_star),\n",
    "        pos_m       = pos,\n",
    "        head_deg    = head,\n",
    "        dir_label   = label\n",
    "    )\n",
    "\n",
    "    out.write(overlay)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "print(\"DONE — saved to lab3_output.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b895fc9",
   "metadata": {},
   "source": [
    "### Hoàn thành Lab\n",
    "\n",
    "Bạn đã hoàn thành bài lab cuối cùng của học phần.  \n",
    "Tại thời điểm này, toàn bộ các thành phần cốt lõi đã được tích hợp thành một hệ thống giữ làn hoàn chỉnh, xuyên suốt từ thu nhận hình ảnh thời gian thực, phân đoạn làn bằng học sâu, xử lý hình học, ổn định tín hiệu cho đến điều khiển vòng kín.\n",
    "\n",
    "Lab này tổng hợp và củng cố các kiến thức, kỹ năng đã học trong suốt khóa học, cho thấy cách các khái niệm lý thuyết được kết nối để tạo nên một hệ thống tự hành hoạt động thực tế. Pipeline hoàn chỉnh này là nền tảng vững chắc cho các thí nghiệm nâng cao, tối ưu hiệu năng và các hướng nghiên cứu tiếp theo trong lĩnh vực xe tự hành và hệ thống thông minh."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
